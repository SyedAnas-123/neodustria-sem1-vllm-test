models:
  # 1. Automotive Model
  - id: neodustria-auto-engineer-v0
    hf_repo: "neodustria-company/llama3-8b-auto-base"
    revision: "main"  
    quantization: awq   # No quantization --> for Quantization use awq or fp16 or gptq
    max_tokens: 2048
    gpu_memory: "20GB"
    domain: "automotive"
    role: "reasoning"

  # 2. Construction Model
  - id: neodustria-const-engineer-v0
    hf_repo: "Qwen/Qwen2.5-7B-Instruct"
    revision: "main"
    quantization: awq
    max_tokens: 2048
    gpu_memory: "20GB"
    domain: "construction"
    role: "reasoning"

  # 3. General Fallback Model
  - id: neodustria-general-v0
    hf_repo: "mistralai/Mistral-7B-Instruct-v0.3"
    revision: "main"
    quantization: awq
    max_tokens: 2048
    gpu_memory: "16GB"
    domain: "general"
    role: "fallback"